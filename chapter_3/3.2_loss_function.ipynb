{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "036fd86a",
   "metadata": {},
   "source": [
    "## 3.3. 손실 함수\n",
    "### 3.3.1. 평균 제곱 오차 손실\n",
    "- MSE(Mean Squared Error): 출력(y_hat)과 타깃(y)이 연속값인 회귀 문제에 사용 \n",
    "- 예측과 타깃값의 차이를 제곱하여 평균 \n",
    "- \"평균 절댓값 오차\"(MAE: mean absolute error), \"평균 제곱근 오차\"(RMSE: root mean squared error) 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db71136d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.5505, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "outputs = torch.randn(3,5,requires_grad=True)\n",
    "targets = torch.randn(3,5)\n",
    "loss = mse_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5073d66",
   "metadata": {},
   "source": [
    "### 3.3.2. 범주형 크로스 엔트로피 손실 (Categorical Cross-Entropy)\n",
    "- 다중 분류 문제에 사용 (출력이 클래스 소속 확률에 대한 예측)\n",
    "- y: 모든 클래스에 대한 다항 분포를 나타내는 원소 n개로 이뤄진 벡터\n",
    "    - Multinomial Distribution: 벡터 원소 합 1, 모든 원소 양수\n",
    "    - 하나의 클래스만 정답이면 \"원-핫 벡터\"\n",
    "- y_hat: 다항 분포에 대한 신경망의 예측 (n개 벡터)\n",
    "\n",
    "<신경망 출력과 손실 함수 간 관계 결정 정보 4가지>\n",
    "- 1) 수 범위 제한\n",
    "- 2) 소프트맥스 함수의 지수 함수 입력 음수(--> 매우작은수), 양수(-->매우큰수)\n",
    "- 3) 신경망의 출력은 소프트맥스 함수를 사용하기 직전의 벡터라고 가정\n",
    "- 4) 로그 함수는 지수 함수의 역함수, long(exp(x)) = x\n",
    "--> 지수 함수(소프트맥스)& 로그 함수(크로스엔트로피 계산)를 간소화 --> 너무 작거나 큰 값 피함.\n",
    "- --> 이런 간소화로 소프트맥스 함수 사용하지 않고, CrossEntropyLoss() 사용해 확률 분포 최적화 가능\n",
    "    - CrossEntropyLoss(): LogSoftmax() + LogSoftmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e3a8a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0814, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\"\"\" 각 입력이 클래스 하나의 속하고,\n",
    "각 클래스에는 고유한 인덱스가 있다고 가정 \n",
    "--> 인덱스를 모델 출력으로 변환하는 매우 효율적인 계산 가능 \"\"\"\n",
    "\n",
    "outputs = torch.randn(3,5,requires_grad=True)\n",
    "targets = torch.tensor([1,0,3], dtype=torch.int64)\n",
    "# 각 샘플의 정답 클래스에 해당하는 인덱스를 나타내는 원소 3개\n",
    "\n",
    "loss = ce_loss(outputs, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895e3a24",
   "metadata": {},
   "source": [
    "### 3.3.3. 이진 크로스 엔트로피 손실(Binary cross-entropy: BCE)\n",
    "- 이중 클래스 분류(이진 분류) 작업에 효율적\n",
    "- 예제) <레스토랑 리뷰 감성 분석하기> (3,6절)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde65f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7640],\n",
      "        [0.8272],\n",
      "        [0.4852],\n",
      "        [0.2810]], grad_fn=<SigmoidBackward0>)\n",
      "tensor(0.7695, grad_fn=<BinaryCrossEntropyBackward0>)\n"
     ]
    }
   ],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "probabilities = sigmoid(torch.randn(4,1,requires_grad=True))\n",
    "# 시그모이드 이용 이진확률벡터 만들기\n",
    "\n",
    "targets = torch.tensor([1,0,1,0], dtype=torch.float32).view(4,1)\n",
    "# 정답(y)을 0과 1로 이뤄진 벡터로 만들기\n",
    "\n",
    "loss = bce_loss(probabilities, targets)\n",
    "# 크로스 엔트로피 손실 계산\n",
    "\n",
    "print(probabilities)\n",
    "print(loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
